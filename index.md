---
layout: home
title: Home
list_title: >-
    <abbr title="Recent 10">R10</abbr> Posts
nav_priority: 0
---

I am Rong "Mantle" Bao, a third-year Computer Science undergraduate at Hangzhou Dianzi University. Welcome to my blog, where I bake all my potatoes.

## About me

* He/him
* GitHub: <https://github.com/CSharperMantle>
* Email: <rong.bao@csmantle.top>
* Natural languages:
  * `zh-cmn-Hans-CN` (native)
  * `zh-wuu-Hans-CN` (native)
  * `en` (near native)
* Developing personal projects

### Skills

* Polyglot, most enjoy C/Rust/TypeScript
* Reverse engineering, messing around with <abbr title="Operating System">OS</abbr> and <abbr title="Instruction Set Architecture">ISA</abbr>
* Bare-metal, desktop native, single-pagge WebApps development
* Experiences with x86-64 assembly, RISC-V/LoongArch <abbr title="Instruction Set Architecture">ISA</abbr>s and microarch implementation
* [Mozilla Level 1 Commit Access](https://bugzilla.mozilla.org/user_profile?user_id=774743), active maintainer of SpiderMonkey's RV64 JIT backend.

<details id="details-ai-attitudes">
  <summary>My attitudes towards <abbr title="Artificial Intelligence">AI</abbr></summary>
  <ul>
    <li><span>Machine learning problems are analytical and statistical problems.</span></li>
    <li><span>Neural networks are good at discovering patterns not obvious to traditional approaches.</span></li>
    <li><span><abbr title="Large Language Model">LLM</abbr>s are probabilistic token predictors. They often intrinsically hallucinate.</span></li>
    <li><span>Garbage in, garbage out. Observation in, imitation out.</span></li>
    <li><span>I do use <abbr title="Large Language Model">LLM</abbr>s to brainstorm ideas.</span></li>
    <li><span>I do use <abbr title="Large Language Model">LLM</abbr>s to perform repetitive clerical work and typographical proofreading.</span></li>
    <li><span>I do chat with <abbr title="Large Language Model">LLM</abbr>s to have fun in my spare time.</span></li>
    <li><span>I do use generative models to craft images for hobby use.</span></li>
    <li><span>I do <em>not</em> use <abbr title="Large Language Model">LLM</abbr>s to write code for production use.</span></li>
    <li><span>I do <em>not</em> use <abbr title="Large Language Model">LLM</abbr>s to write casual articles, like blogs.</span></li>
    <li><span>I do <em>not</em> use <abbr title="Large Language Model">LLM</abbr>s to write academic articles or carry out research in place of myself.</span></li>
    <li><span>I do <em>not</em> use <abbr title="Large Language Model">LLM</abbr>s as a search engine.</span></li>
    <li><span>I do <em>not</em> trust <abbr title="Large Language Model">LLM</abbr>s as a sole source of information.</span></li>
    <li><span>I do <em>not</em> accept responses from <abbr title="Large Language Model">LLM</abbr>s without verification.</span></li>
    <li><span>I believe the loopholes and waivers in <abbr title="Large Language Model">LLM</abbr> hosting companies' <abbr title="End-User License Agreement">EULA</abbr> put much personal information at risk.</span></li>
    <li><span>I believe <abbr title="Large Language Model">LLM</abbr>s are energy hogs that should be used with conservation in mind.</span></li>
    <li><span>I believe <abbr title="Large Language Model">LLM</abbr>s are becoming more performant as theories and technologies evolve.</span></li>
  </ul>
</details>

------
